# -*- coding: utf-8 -*-
"""Copy of finalvls

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tZk8NW-EiBY6S63uMmjzPPiH0823TAom
"""

!pip install torch==2.5.1

import torch
torchversion = torch.__version__

!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html
!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html
!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git

# 1. 卸载当前 PyTorch 和 torch-scatter 等
!pip uninstall -y torch torchvision torchaudio torch-scatter torch-sparse torch-cluster torch-spline-conv

# 2. 安装兼容版本（PyTorch 2.3.0 + CUDA 12.1）
!pip install torch==2.3.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 3. 安装 PyG 所需组件（torch-scatter 等）
!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.3.0+cu121.html
!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.3.0+cu121.html
!pip install git+https://github.com/pyg-team/pytorch_geometric.git

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount("/content/gdrive")
# %cd /content/gdrive/MyDrive/3

from scipy.sparse import issparse
import torch
import numpy as np
import joblib

def extract_weight_array(w_dict):
    """将字典类型的权重展平为二维数组"""
    if not isinstance(w_dict, dict):
        return None
    try:
        keys = sorted(w_dict.keys(), key=lambda x: int(x) if str(x).isdigit() else str(x))
        collected = []
        for k in keys:
            v = w_dict[k]
            if isinstance(v, list):
                arr = np.array(v)
                if arr.ndim == 1:
                    arr = arr[:, None]
                collected.append(arr)
        if not collected:
            return None
        return np.hstack(collected)
    except Exception as e:
        print(f"⚠️ extract_weight_array 失败: {e}")
        return None


def build_samples(matrix_path, b_path, weight_path, source_tag):
    matrices = joblib.load(matrix_path)
    b_list = joblib.load(b_path)
    weight_list = joblib.load(weight_path)

    min_len = min(len(matrices), len(b_list), len(weight_list))

    if len(matrices) != len(b_list) or len(matrices) != len(weight_list):
        print(f"⚠️ [警告] 三个列表长度不一致（将使用前 {min_len} 条）：")
        print(f"   matrix: {len(matrices)}, b: {len(b_list)}, weight: {len(weight_list)}")

    matrices = matrices[:min_len]
    b_list = b_list[:min_len]
    weight_list = weight_list[:min_len]

    samples = []
    skipped = 0

    for i in range(min_len):
        try:
            matrix = matrices[i].toarray() if issparse(matrices[i]) else matrices[i]
            b = b_list[i]
            w_raw = weight_list[i]

            weight = extract_weight_array(w_raw)
            if weight is None:
                skipped += 1
                continue

            samples.append((matrix, b, weight, source_tag))
        except Exception as e:
            print(f"[跳过] 第 {i} 个样本处理失败: {e}")
            skipped += 1
            continue

    print(f"✅ {source_tag} 加载成功: {len(samples)} 个有效样本，跳过 {skipped} 个无效样本")
    return samples

data_8 = build_samples("sparse8_matrix_list.pkl", "sparse8_b_list.pkl", "weights_list_8.pkl", "8")
data_9 = build_samples("sparse9_matrix_list.pkl", "sparse9_b_list.pkl", "weights_list_9.pkl", "9")
data_10 = build_samples("sparse10_matrix_list.pkl", "sparse10_b_list.pkl", "weights_list_10.pkl", "10")

import joblib
import numpy as np
from scipy.sparse import issparse

# 加载路径
matrix_path = "sparse_pkl_data_matrix.pkl"
b_path = "sparse_pkl_data_b.pkl"
w_path = "sparse_pkl_data_w.pkl"

# 加载文件
matrices = joblib.load(matrix_path)
b_list = joblib.load(b_path)
w_list = joblib.load(w_path)

def flatten_weight_array(weight_array):
    """将三维数组展平为二维 (N, d)"""
    if isinstance(weight_array, np.ndarray) and weight_array.ndim == 3:
        return weight_array.reshape(-1, weight_array.shape[-1])
    return None

samples = []
skipped = 0

min_len = min(len(matrices), len(b_list), len(w_list))

for i in range(min_len):
    try:
        matrix = matrices[i].toarray() if issparse(matrices[i]) else matrices[i]
        b = b_list[i]
        w_raw = w_list[i]
        weight = flatten_weight_array(w_raw)
        if weight is None:
            skipped += 1
            continue
        samples.append((matrix, b, weight, "test"))
    except Exception as e:
        print(f"[跳过] 第 {i} 个样本出错: {e}")
        skipped += 1
        continue

print(f"✅ 总计生成 {len(samples)} 个样本，跳过 {skipped} 个")

# 保存为 .pkl 格式
joblib.dump(samples, "test.pkl")
print("✅ 已保存为 test.pkl")
import torch
import joblib

samples = joblib.load("test.pkl")
torch.save(samples, "test.pt")

import torch
import joblib
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
import numpy as np

# 加载 test.pt（你之前保存的 test.pt 文件）
test_tuples = torch.load("test.pt", map_location=torch.device("cpu"))  # 强制加载为 CPU

# 工具函数：将数据转换为 PyG 的 Data 格式
def tuple_to_data(tuples):
    data_list = []
    for A, b, w, tag in tuples:
        A_tensor = torch.tensor(A, dtype=torch.float)
        b_tensor = torch.tensor(b, dtype=torch.float).view(-1, 1)
        w_tensor = torch.tensor(w, dtype=torch.float)

        edge_index = (A_tensor != 0).nonzero(as_tuple=False).t().contiguous()
        edge_weight = A_tensor[edge_index[0], edge_index[1]]

        data = Data(x=w_tensor, edge_index=edge_index, edge_attr=edge_weight, y=b_tensor)
        data_list.append(data)
    return data_list

# 转换为 Data 列表并构造 DataLoader
test_dataset = tuple_to_data(test_tuples)
test_loader = DataLoader(test_dataset, batch_size=32)

print(f"✅ Test dataset loaded with {len(test_dataset)} samples.")

import torch
import joblib

samples = joblib.load("test.pkl")
torch.save(samples, "test.pt")

import random
import torch

# 合并数据
all_data = data_8 + data_9 + data_10
random.shuffle(all_data)  # 打乱顺序

# 划分训练、验证、测试集（8:1:1）
total_len = len(all_data)
train_len = int(total_len * 0.8)
val_len = int(total_len * 0.1)

train_data = all_data[:train_len]
val_data = all_data[train_len:train_len + val_len]
test_data = all_data[train_len + val_len:]

# 根据 source_tag 再次划分测试集
test_8 = [d for d in test_data if d[3] == "8"]
test_9 = [d for d in test_data if d[3] == "9"]
test_10 = [d for d in test_data if d[3] == "10"]

# 输出信息
print(f"📦 Train: {len(train_data)}")
print(f"📦 Val: {len(val_data)}")
print(f"📦 Test: {len(test_data)}")
print(f"   ├── test_8: {len(test_8)}")
print(f"   ├── test_9: {len(test_9)}")
print(f"   └── test_10: {len(test_10)}")

# 如需保存，可使用以下代码（如果你想保留）
# torch.save(train_data, "train.pt")
# torch.save(val_data, "val.pt")
# torch.save(test_data, "test.pt")
# torch.save(test_8, "test_8.pt")
# torch.save(test_9, "test_9.pt")
# torch.save(test_10, "test_10.pt")
import torch

# 保存到当前工作目录
torch.save(train_data, "train.pt")
torch.save(val_data, "val.pt")
torch.save(test_data, "test.pt")
torch.save(test_8, "test_8.pt")
torch.save(test_9, "test_9.pt")
torch.save(test_10, "test_10.pt")

print("✅ 所有文件保存完成。")

import os

for fname in ["train.pt", "val.pt", "test.pt", "test_8.pt", "test_9.pt", "test_10.pt"]:
    print(f"{fname}: {'存在 ✅' if os.path.exists(fname) else '不存在 ❌'}")

import torch
from torch_geometric.data import Data
from scipy.sparse import issparse

def tuple_to_data(samples, max_len=30):
    data_list = []
    qn = max_len // 3

    for i, (matrix, b, weight, tag) in enumerate(samples):
        try:
            # 1. 稀疏矩阵转稠密
            if issparse(matrix):
                matrix = matrix.toarray()
            matrix = torch.tensor(matrix, dtype=torch.float32, device='cpu')
            row, col = torch.where(matrix != 0)
            edge_index = torch.stack([row, col], dim=0).long()
            edge_attr = matrix[row, col].unsqueeze(1)

            # 2. 处理 b（支持嵌套字符串或数字）
            flat_b = []
            for val in b:
                if isinstance(val, (list, tuple)):
                    flat_b.extend([float(v) for v in val])
                else:
                    flat_b.append(float(val))
            x = torch.tensor([[v] for v in flat_b], dtype=torch.float32, device='cpu')

            # 3. 标签处理
            y_raw = torch.tensor(weight, dtype=torch.float32, device='cpu').flatten()
            if y_raw.shape[0] < max_len:
                y_raw = torch.cat([y_raw, torch.zeros(max_len - y_raw.shape[0], device='cpu')])
            y = y_raw[:max_len].view(qn, 3)

            # 4. 构建图数据
            data = Data(
                edge_index=edge_index,
                edge_attr=edge_attr,
                x=x,
                y=y
            )
            data_list.append(data)

        except Exception as e:
            print(f"[跳过] 第 {i} 个样本转换失败: {e}")
            print(f"  ▶️ b内容示例: {str(b)[:100]}")
            continue

    return data_list

from torch_geometric.data import Data

def force_data_to_cpu(dataset):
    for i in range(len(dataset)):
        data = dataset[i]
        new_data = Data()
        for key in data.keys():  # ✅ 注意这里加上括号 keys()
            item = data[key]
            if isinstance(item, torch.Tensor):
                new_data[key] = item.cpu()
            else:
                new_data[key] = item
        dataset[i] = new_data

# 第一步：加载原始数据
train_tuples = torch.load("train.pt")
val_tuples = torch.load("val.pt")
test_8_tuples = torch.load("test_8.pt")

# 第二步：转换为图结构（PyG的Data对象）
train_dataset = tuple_to_data(train_tuples)
val_dataset = tuple_to_data(val_tuples)
test_8_dataset = tuple_to_data(test_8_tuples)


train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32)


# 第三步：DataLoader 加载
from torch_geometric.loader import DataLoader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32)
test_8_loader = DataLoader(test_8_dataset, batch_size=32)

from torch_geometric.loader import DataLoader

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64)
test_loader_8 = DataLoader(test_8, batch_size=64)

from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout, Tanh
import torch.nn.functional as F
from torch_geometric.nn import GATConv, global_mean_pool, MessagePassing, conv
from torch_geometric.utils import add_self_loops, degree
from torch_scatter import scatter_add
import copy
from torch_sparse import sum as sparsesum
from torch_sparse import mul
from torch_sparse import SparseTensor


def directed_norm(adj):
  in_deg = sparsesum(adj, dim=0)
  in_deg_inv_sqrt = in_deg.pow_(-0.5)
  in_deg_inv_sqrt.masked_fill_(in_deg_inv_sqrt == float("inf"), 0.0)

  out_deg = sparsesum(adj, dim=1)
  out_deg_inv_sqrt = out_deg.pow_(-0.5)
  out_deg_inv_sqrt.masked_fill_(out_deg_inv_sqrt == float("inf"), 0.0)
  adj = mul(adj, out_deg_inv_sqrt.view(-1, 1))
  adj = mul(adj, in_deg_inv_sqrt.view(1, -1))
  return adj


class GCNConv_lap(MessagePassing):
  def __init__(self, in_channels, out_channels):
    self.in_channels = in_channels
    self.out_channels = out_channels
    super(GCNConv_lap, self).__init__(aggr='add')
    self.lin = torch.nn.Linear(in_channels, out_channels)

  def forward(self, x, edge_index, edge_weight):
    edge_index_self_loop, _ = add_self_loops(edge_index, num_nodes=x.size(0))
    edge_weight_self_loop = torch.cat((edge_weight.flatten(), torch.ones(x.size(0)).to("cuda")), dim=0)

    x = self.lin(x)

    row, col = edge_index_self_loop
    deg = scatter_add(torch.abs(edge_weight_self_loop), col, dim=0, dim_size=x.size(0))
    deg_inv_sqrt = deg.pow(-0.5)
    norm = deg_inv_sqrt[row] * torch.abs(edge_weight_self_loop) * deg_inv_sqrt[col]

    return self.propagate(edge_index_self_loop, x=x, norm=norm, edge_weight_self_loop=edge_weight_self_loop)

  def message(self, x_i, x_j, norm, edge_weight_self_loop):
    x_j = torch.sign(edge_weight_self_loop).view(-1,1)*x_j
    return (norm.view(-1, 1) * x_j)


class DGNNConv(torch.nn.Module):
  def __init__(
      self,
      mconv: conv.MessagePassing,
      alpha: float = 0.5,
      root_weight: bool = True,
  ):
    super().__init__()
    self.alpha = alpha
    self.root_weight = root_weight
    self.conv_in = copy.deepcopy(mconv)
    self.conv_out = copy.deepcopy(mconv)

    self.reset_parameters()

  def reset_parameters(self):
    self.conv_in.reset_parameters()
    self.conv_out.reset_parameters()

  def forward(self, x, edge_index, edge_attr):
    row, col = edge_index
    num_nodes = x.shape[0]
    adj = SparseTensor(row=row, col=col, sparse_sizes=(num_nodes, num_nodes))
    self.adj_norm = directed_norm(adj)
    adj_t = SparseTensor(row=col, col=row, sparse_sizes=(num_nodes, num_nodes))
    self.adj_t_norm = directed_norm(adj_t)

    x_in = self.conv_in(self.adj_norm @ x, edge_index, edge_attr)
    x_out = self.conv_out(self.adj_t_norm @ x, edge_index.flip(0), edge_attr)

    out = self.alpha * x_out + (1 - self.alpha) * x_in

    return out


import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn import Linear, ReLU
from torch_geometric.nn import global_mean_pool, GATConv, GCNConv as GCNConv_lap, MessagePassing
import copy

class DGNNConv(nn.Module):
    def __init__(self, mconv: MessagePassing, alpha: float = 0.5, root_weight: bool = True):
        super().__init__()
        self.alpha = alpha
        self.root_weight = root_weight
        self.conv_in = copy.deepcopy(mconv)
        self.conv_out = copy.deepcopy(mconv)

    def reset_parameters(self):
        self.conv_in.reset_parameters()
        self.conv_out.reset_parameters()

    def forward(self, x, edge_index, edge_attr):
        x_in = self.conv_in(x, edge_index, edge_attr)
        x_out = self.conv_out(x, edge_index.flip(0), edge_attr)
        return self.alpha * x_out + (1 - self.alpha) * x_in

class DGNN(nn.Module):
    def __init__(self, n_x, qn, dim_h=256, alpha=0.5):
        super().__init__()
        self.qn = qn
        self.output_dim = qn * 3

        self.hidden_channels_gcn = dim_h * 2
        self.hidden_channels_gat = self.hidden_channels_gcn * 2

        self.conv1 = DGNNConv(GCNConv_lap(n_x, self.hidden_channels_gcn), alpha)
        self.conv2 = DGNNConv(GCNConv_lap(self.hidden_channels_gcn, self.hidden_channels_gcn), alpha)

        self.gat_conv1 = GATConv(self.hidden_channels_gcn, self.hidden_channels_gat)
        self.gat_conv2 = GATConv(self.hidden_channels_gat, self.hidden_channels_gat)

        self.out = nn.Sequential(
            Linear(self.hidden_channels_gat, self.hidden_channels_gat),
            ReLU(),
            Linear(self.hidden_channels_gat, self.output_dim)
        )

    def forward(self, x, edge_index, edge_weight, batch):
        x = F.relu(self.conv1(x, edge_index, edge_weight))
        x = F.relu(self.conv2(x, edge_index, edge_weight))
        x = F.relu(self.gat_conv1(x, edge_index, edge_weight))
        x = F.relu(self.gat_conv2(x, edge_index, edge_weight))
        x = global_mean_pool(x, batch)
        x = self.out(x)
        return x.view(-1, self.qn, 3)   # 动态 reshape

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch_geometric.loader import DataLoader
from torch_geometric.data import Data

# ✅ 工具函数：强制将数据从 GPU 转到 CPU
def force_data_to_cpu(dataset):
    for i in range(len(dataset)):
        data = dataset[i]
        new_data = Data()
        for key in data.keys():
            item = data[key]
            if isinstance(item, torch.Tensor):
                new_data[key] = item.cpu()
            else:
                new_data[key] = item
        dataset[i] = new_data

# ✅ 强制训练数据和验证数据都在 CPU 上
force_data_to_cpu(train_dataset)
force_data_to_cpu(val_dataset)

# ✅ 构建 DataLoader
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size)

# ✅ 设备选择
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ✅ 动态确定输入维度和 qn
example = train_dataset[0]
n_x = example.x.shape[1]
qn = example.y.shape[0]  # 假设你用了 max_len=30，3列，qn=10

# ✅ 初始化模型（你自己提供的 DGNN 实现）
model = DGNN(n_x=n_x, qn=qn, dim_h=256, alpha=0.5).to(device)

# ✅ 模型输出检查
sample = example
model.eval()
with torch.no_grad():
    pred = model(
        sample.x.to(device),
        sample.edge_index.to(device),
        sample.edge_attr.to(device),
        torch.zeros(sample.x.shape[0], dtype=torch.long).to(device)  # dummy batch
    )
    print("✅ Model output shape:", pred.shape)  # 应为 [1, qn, 3]

# ✅ 损失函数与优化器
loss_fn = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.005)
scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)

# ✅ 训练
n_epochs = 50
best_val_loss = float("inf")
save_path = "best_model.pth"

for epoch in range(n_epochs):
    model.train()
    train_losses = []

    for batch in train_loader:
        batch = batch.to(device)
        optimizer.zero_grad()

        pred = model(
            batch.x.to(device),
            batch.edge_index.to(device),
            batch.edge_attr.to(device),
            batch.batch.to(device)
        )
        y = batch.y.to(device).view(pred.size(0), qn, 3)

        loss = loss_fn(pred, y)
        loss.backward()
        optimizer.step()
        train_losses.append(loss.item())

    train_mse = sum(train_losses) / len(train_losses)
    print(f"📘 Epoch {epoch} | Train MSE: {train_mse:.6f}")

    # ✅ 验证
    model.eval()
    val_losses = []
    with torch.no_grad():
        for batch in val_loader:
            batch = batch.to(device)
            pred = model(
                batch.x.to(device),
                batch.edge_index.to(device),
                batch.edge_attr.to(device),
                batch.batch.to(device)
            )
            y = batch.y.to(device).view(pred.size(0), qn, 3)
            loss = loss_fn(pred, y)
            val_losses.append(loss.item())

    val_mse = sum(val_losses) / len(val_losses)
    print(f"📗 Epoch {epoch} | Val MSE: {val_mse:.6f}")

    if val_mse < best_val_loss:
        best_val_loss = val_mse
        torch.save(model.state_dict(), save_path)
        print(f"✅ Best model saved at epoch {epoch} | Val MSE: {best_val_loss:.6f}")

    scheduler.step()

test_8_tuples = torch.load("test_8.pt")
test_9_tuples = torch.load("test_9.pt")
test_10_tuples = torch.load("test_10.pt")

import torch
from torch_geometric.loader import DataLoader
from torch_geometric.data import Data
from scipy.sparse import issparse

def tuple_to_data(samples, max_len=30):
    data_list = []
    for i, (matrix, b, weight, tag) in enumerate(samples):
        try:
            # 1. 稀疏矩阵转稠密
            if issparse(matrix):
                matrix = matrix.toarray()
            matrix = torch.tensor(matrix, dtype=torch.float32)
            row, col = torch.where(matrix != 0)
            edge_index = torch.stack([row, col], dim=0).long()
            edge_attr = matrix[row, col].unsqueeze(1)

            # 2. 节点特征 b 处理
            flat_b = []
            for val in b:
                if isinstance(val, (list, tuple)):
                    flat_b.extend([float(v) for v in val])
                else:
                    flat_b.append(float(val))
            x = torch.tensor([[v] for v in flat_b], dtype=torch.float32)

            # 3. 标签处理
            y_raw = torch.tensor(weight, dtype=torch.float32).flatten()
            y = y_raw[:max_len] if y_raw.shape[0] >= max_len else torch.cat([
                y_raw, torch.zeros(max_len - y_raw.shape[0])
            ])
            qn = max_len // 3
            y = y.view(qn, 3)

            # 4. 构建图
            data = Data(
                edge_index=edge_index.cpu(),
                edge_attr=edge_attr.cpu(),
                x=x.cpu(),
                y=y.cpu()
            )
            data_list.append(data)

        except Exception as e:
            print(f"[跳过] 第 {i} 个样本失败: {e}")
            continue
    return data_list

def predict_on_test(test_tuples, true_qn, model_path="best_model.pth", save_path="test_pred.pt"):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. 构造图数据集
    test_dataset = tuple_to_data(test_tuples, max_len=30)
    if len(test_dataset) == 0:
        print("❌ 没有有效测试样本，跳过预测。")
        return

    test_loader = DataLoader(test_dataset, batch_size=32)

    # 2. 初始化模型
    example = test_dataset[0]
    n_x = example.x.shape[1]
    model = DGNN(n_x=n_x, qn=10, dim_h=256, alpha=0.5).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    # 3. 批量推理
    all_preds = []
    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            out = model(
                batch.x.to(device),
                batch.edge_index.to(device),
                batch.edge_attr.to(device),
                batch.batch.to(device)
            )  # 输出: (B, 10, 3)

            out = out[:, :true_qn, :]  # ⚠️ 裁剪到指定长度
            all_preds.append(out.cpu())

    # 4. 拼接保存
    final_tensor = torch.cat(all_preds, dim=0)  # (N, true_qn, 3)
    torch.save(final_tensor, save_path)
    print(f"✅ 已保存预测结果到: {save_path} | 形状: {final_tensor.shape}")
# 假设你已经准备好了 test_8_tuples 等
predict_on_test(test_8_tuples, true_qn=8, save_path="test_8_pred.pt")
predict_on_test(test_9_tuples, true_qn=9, save_path="test_9_pred.pt")
predict_on_test(test_10_tuples, true_qn=10, save_path="test_10_pred.pt")

import torch

tensor = torch.load("test_9_pred.pt", map_location="cpu")
print(tensor.shape)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch_geometric.loader import DataLoader
from torch_geometric.data import Data



example = test_dataset[0]
n_x = example.x.shape[1]
qn = example.y.shape[0] if hasattr(example, "y") else 10  # 若无 y，可手动指定
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DGNN(n_x=n_x, qn=qn, dim_h=256, alpha=0.5).to(device)
model.load_state_dict(torch.load("best_model.pt", map_location=device))
model.eval()

# Step 3: 推理
all_preds = []
with torch.no_grad():
    for batch in test_loader:
        batch = batch.to(device)
        out = model(
            batch.x,
            batch.edge_index,
            batch.edge_attr,
            batch.batch
        )  # 输出形状: (B, qn, 3)
        out = out[:, :qn, :]  # 若模型输出大于实际 qn，则裁剪
        all_preds.append(out.cpu())

# Step 4: 保存预测结果
final_tensor = torch.cat(all_preds, dim=0)  # (N, qn, 3)
torch.save(final_tensor, "test_pred.pt")
print(f"✅ 推理完成，预测结果已保存至 test_pred.pt，形状为: {final_tensor.shape}")

from google.colab import drive
drive.mount('/content/drive')

# 如果你已经知道文件在 Google Drive 中的路径
file_path = "/content/drive/MyDrive/3/best_model.pt"  # 根据实际路径调整

# 加载模型
model.load_state_dict(torch.load(file_path, map_location=device))

import torch
import time
from torch_geometric.loader import DataLoader
from torch_geometric.data import Data
from scipy.sparse import issparse

def tuple_to_data(samples, max_len=30):
    data_list = []
    for i, (matrix, b, weight, tag) in enumerate(samples):
        try:
            if issparse(matrix):
                matrix = matrix.toarray()
            matrix = torch.tensor(matrix, dtype=torch.float32)
            row, col = torch.where(matrix != 0)
            edge_index = torch.stack([row, col], dim=0).long()
            edge_attr = matrix[row, col].unsqueeze(1)

            flat_b = []
            for val in b:
                if isinstance(val, (list, tuple)):
                    flat_b.extend([float(v) for v in val])
                else:
                    flat_b.append(float(val))
            x = torch.tensor([[v] for v in flat_b], dtype=torch.float32)

            y_raw = torch.tensor(weight, dtype=torch.float32).flatten()
            y = y_raw[:max_len] if y_raw.shape[0] >= max_len else torch.cat([
                y_raw, torch.zeros(max_len - y_raw.shape[0])
            ])
            qn = max_len // 3
            y = y.view(qn, 3)

            data = Data(
                edge_index=edge_index.cpu(),
                edge_attr=edge_attr.cpu(),
                x=x.cpu(),
                y=y.cpu()
            )
            data_list.append(data)

        except Exception as e:
            print(f"[跳过] 第 {i} 个样本失败: {e}")
            continue
    return data_list

def predict_on_test(test_tuples, true_qn, model_path="best_model.pth", save_path="test_pred.pt"):
    import time
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    test_dataset = tuple_to_data(test_tuples, max_len=30)
    if len(test_dataset) == 0:
        print("❌ 没有有效测试样本，跳过预测。")
        return

    test_loader = DataLoader(test_dataset, batch_size=32)

    example = test_dataset[0]
    n_x = example.x.shape[1]
    model = DGNN(n_x=n_x, qn=10, dim_h=256, alpha=0.5).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    all_preds = []

    start_time = time.time()  # ⏱️开始计时
    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            out = model(
                batch.x.to(device),
                batch.edge_index.to(device),
                batch.edge_attr.to(device),
                batch.batch.to(device)
            )
            out = out[:, :true_qn, :]
            all_preds.append(out.cpu())
    end_time = time.time()  # ⏱️结束计时

    final_tensor = torch.cat(all_preds, dim=0)
    torch.save(final_tensor, save_path)

    print(f"✅ 已保存预测结果到: {save_path} | 形状: {final_tensor.shape}")
    print(f"🕒 推理耗时: {end_time - start_time:.4f} 秒")

# 示例调用
predict_on_test(test_8_tuples, true_qn=8, save_path="test_8_pred.pt")
predict_on_test(test_9_tuples, true_qn=9, save_path="test_9_pred.pt")
predict_on_test(test_10_tuples, true_qn=10, save_path="test_10_pred.pt")